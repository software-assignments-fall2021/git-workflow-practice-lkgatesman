# Apple CSAM Software Controversy

The article that I chose is about the controversy regarding Apple's new (but not yet released) CSAM detection
software: https://techcrunch.com/2021/09/03/apple-csam-detection-delayed/

## My Thoughts

CSAM Software is software that analyzes images to determine if they contain CSAM (Child Sex Abuse Material),
and Apple is planning to roll their own CSAM Software, "NeuralHash", that will work within images on user devices.

I think this situation is very interesting because there are two understandable sides to the argument. The first is that users don't want Apple accessing the images on their devices, as it is a privacy concern. Apple has stated that the NeuralHash technology operates "without having to possess the image or knowing the contents of the image". Many people, including the American Civil Liberties Union, have urged Apple to not release their NeuralHash software. But on the other hand, Apple and others (including the National Center for Missing and Exploited Children, whom Apple worked with when developing the software) want to catch child predators and end child sex abuse.

I think that this software would be helpful, but I also understand concerns that other entities (like governments) using this software for bad purposes - which is entirely possible. However, if NeuralHash is actually efficient and demonstrates ability to catch child predators, I think that this conversation over privacy needs to be re-visited. If the software truly doesn't know the actual content of the images, like Apple says it doesn't, then I think NeuralHash would be a great tool. I will continue to follow this story as it develops, and as Apple decides whether or not it will release NeuralHash or not.

### Comment by Seunggun Lee

As Lauren described, this article is very interesting because of both the power and curse of CSAM software. I feel this dichotamy - which is often a gray scale problem, rather than a black-and-white one - is common throughout the tech scene. I think this issue is especially relevant today, where various government bodies and private companies are able to utilize surveillance technology to monitor individuals. As active particpants in the tech field (both as users and developers), I think it's crucial for us to be mindful of the direction of technology and its power.


### Comment by Jin Hyeong Kim
Right off the bat, I thought CSAM was something that had to do with Apple's ever-improving camera functionality and the recently added ability to approximate distances between the apple product and an object within the scope of said product's camera. I digress.

Child sexual abuse detection technology. Sounds like a daunting task, but one which I'm very interested seeing how Apple will go about implementing. While a part of me would like to advocate technology such as this to further guarantee child protection, I can't help but be reminded of the big 2018 scandal where Mark Zuckerberg decided to leverage Facebook user data. All light speculation, really.
Interesting article nonetheless!
